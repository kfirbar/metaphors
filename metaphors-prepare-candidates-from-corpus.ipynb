{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "import spacy as sp\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from math import log\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import DBSCAN\n",
    "from math import log\n",
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "from itertools import product\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = sp.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = pd.read_csv(\"eval-mod_ours.txt\")\n",
    "\n",
    "metaphor_words = []\n",
    "metaphors = {}\n",
    "\n",
    "for r in eval_data.iterrows():\n",
    "    #tokens = nlp(r[1][\"Metaphor\"].decode('utf-8', errors='ignore').strip().lower())\n",
    "    tokens = nlp(r[1][\"Metaphor\"].strip().lower())\n",
    "    topic = tokens[0]\n",
    "    vehicle = tokens[-1]\n",
    "    if topic.lemma_ not in metaphor_words:\n",
    "        metaphor_words.append(topic.lemma_)\n",
    "    if vehicle.lemma_ not in metaphor_words:\n",
    "        metaphor_words.append(vehicle.lemma_)\n",
    "    if r[1][\"Metaphor\"] not in metaphors:\n",
    "        metaphors[r[1][\"Metaphor\"]] = [topic.lemma_, vehicle.lemma_, \n",
    "                                       [(str(r[1][\"Interpretation\"]).lower(), r[1][\"Freq\"])],\n",
    "                                       [str(r[1][\"Interpretation\"]).lower()]\n",
    "                                      ]\n",
    "    else:\n",
    "        metaphors[r[1][\"Metaphor\"]][2].append((str(r[1][\"Interpretation\"]).lower(), r[1][\"Freq\"]))\n",
    "        metaphors[r[1][\"Metaphor\"]][3].append(str(r[1][\"Interpretation\"]).lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self):\n",
    "        self.vec = []\n",
    "        self.word_count = 0\n",
    "        self.ind2word = {}\n",
    "        self.word2ind = {}\n",
    "        for line in open(\"/Users/Kfir/Documents/corpora/glove.6B/glove.6B.300d.txt\"):\n",
    "            values = line.split(\" \")\n",
    "            v = []\n",
    "            for i in range (1, len(values)):\n",
    "                v.append(float(values[i]))\n",
    "            self.vec.append(v)\n",
    "            self.ind2word[self.word_count] = values[0]\n",
    "            self.word2ind[values[0]] = self.word_count\n",
    "            self.word_count += 1\n",
    "    \n",
    "    def get_vec(self, word):\n",
    "        word = word.strip().lower()\n",
    "        if word in self.word2ind:\n",
    "            return self.vec[self.word2ind[word]]\n",
    "        return None\n",
    "            \n",
    "lang = Lang()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepNode:\n",
    "    def __init__(self, line):\n",
    "        tokens = line.split('\\t')\n",
    "        self.id = int(tokens[0])\n",
    "        self.text = tokens[1].lower()\n",
    "        self.lemma = tokens[2].lower()\n",
    "        self.pos = tokens[3]\n",
    "        self.head = int(tokens[6])\n",
    "        self.dep_type = tokens[7]\n",
    "        self.children = []\n",
    "\n",
    "class DepSentence:\n",
    "    def __init__(self):\n",
    "        self.nodes = []\n",
    "        \n",
    "    def add_word(self, line):\n",
    "        node = DepNode(line)\n",
    "        self.nodes.append(node)\n",
    "        return node\n",
    "        \n",
    "    def rewire(self):\n",
    "        for n in self.nodes:\n",
    "            if n.dep_type != 'ROOT':\n",
    "                self.nodes[n.head].children.append(n)\n",
    "    \n",
    "\n",
    "def is_valid_meaning(p):\n",
    "    #if self.pos in ['JJ', 'JJS', 'RB', 'VBG']:\n",
    "    #if p in ['JJ', 'JJS', 'VBG']:\n",
    "    if p in ['VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'VB']:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "\n",
    "def count_words(dep_corpus_folder):\n",
    "    words = 0\n",
    "    files = [f for f in os.listdir(dep_corpus_folder) if os.path.isfile(os.path.join(dep_corpus_folder, f))]\n",
    "    for f in files:\n",
    "        full_path = os.path.join(dep_corpus_folder, f)\n",
    "        print(\"processing\", full_path)\n",
    "        sentence = None\n",
    "        valid = False\n",
    "        for line in gzip.open(full_path):\n",
    "            if len(line.strip()) > 0:\n",
    "                words += 0\n",
    "                \n",
    "    print(words)\n",
    "        \n",
    "def find_candidates_for(words, dep_corpus_folder):\n",
    "    candidates = {}\n",
    "    files = [f for f in os.listdir(dep_corpus_folder) if os.path.isfile(os.path.join(dep_corpus_folder, f))]\n",
    "    for f in files:\n",
    "        full_path = os.path.join(dep_corpus_folder, f)\n",
    "        print(\"processing\", full_path)\n",
    "        sentence = None\n",
    "        valid = False\n",
    "        for line in gzip.open(full_path):\n",
    "            line = line.decode('utf-8')\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and line[0] != '#':\n",
    "                if sentence is None:\n",
    "                    sentence = DepSentence()\n",
    "                node = sentence.add_word(line)\n",
    "                if node.text in words:\n",
    "                    valid = True\n",
    "            elif sentence is not None:\n",
    "                if valid:\n",
    "                    sentence.rewire()\n",
    "                    for n in sentence.nodes:\n",
    "                        if n.text in words:\n",
    "                            if n.text not in candidates:\n",
    "                                candidates[n.text] = Counter()\n",
    "                            if n.dep_type != 'ROOT' and is_valid_meaning(sentence.nodes[n.head].pos):\n",
    "                                candidates[n.text][sentence.nodes[n.head].text] += 1\n",
    "                            for c in n.children:\n",
    "                                if is_valid_meaning(c.pos):\n",
    "                                    candidates[n.text][c.text] += 1\n",
    "                sentence = None\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing dep_corpus/part-m-00000.gz\n"
     ]
    }
   ],
   "source": [
    "candidates = find_candidates_for(metaphor_words, 'dep_corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(candidates, open( \"candidates-verb-noun.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('using', 43), ('good', 42), ('quick', 37), ('trying', 26), ('sure', 26), ('smooth', 24), ('mixed', 23), ('causing', 21), ('low', 16), ('stirring', 16), ('crazy', 16), ('making', 15), ('baking', 14), ('scraping', 12), ('going', 11), ('little', 11), ('hot', 11), ('incorporated', 10), ('thick', 10), ('cold', 9), ('frying', 9), ('much', 9), ('serving', 7), ('slanting', 7), ('giving', 7), ('dry', 7), ('big', 6), ('mixing', 6), ('cool', 6), ('soft', 6), ('cooking', 6), ('necessary', 6), ('boiling', 6), ('warm', 6), ('adding', 5), ('careful', 5), ('easy', 5), ('brown', 5), ('large', 5), ('looking', 5), ('coated', 5), ('continuing', 5), ('simple', 5), ('beginning', 5), ('icing', 4), ('small', 4), ('simmering', 4), ('creating', 4), ('unhinged', 4), ('working', 4), ('few', 4), ('white', 4), ('bubbling', 4), ('thin', 4), ('stopping', 4), ('fried', 4), ('huge', 4), ('irrational', 4), ('important', 4), ('refrigerate', 4), ('starting', 4), ('mild', 3), ('blended', 3), ('stiff', 3), ('getting', 3), ('leaving', 3), ('top', 3), ('golden', 3), ('hard', 3), ('pretty', 3), ('gentle', 3), ('ready', 3), ('afraid', 3), ('able', 3), ('topping', 3), ('helping', 3), ('allowing', 3), ('such', 3), ('lukewarm', 3), ('bring', 2), ('including', 2), ('moist', 2), ('alternating', 2), ('savory', 2), ('remaining', 2), ('possible', 2), ('putting', 2), ('translucent', 2), ('fragrant', 2), ('discussing', 2), ('pricing', 2), ('tender', 2), ('incorporating', 2), ('jalapeno', 2), ('replacing', 2), ('beating', 2), ('brewing', 2), ('free', 2), ('subconscious', 2), ('balsamic', 2), ('last', 2), ('taking', 2), ('sticky', 2), ('impossible', 2), ('bubbly', 2), ('creamy', 2), ('initial', 2), ('moistened', 2), ('golden-brown', 2), ('terrible', 2), ('solid', 2), ('likely', 2), ('final', 2), ('similar', 2), ('tangzhong', 2), ('tall', 2), ('deep', 2), ('high', 2), ('pulling', 2), ('posting', 2), ('depending', 2), ('odd', 2), ('breaking', 2), ('occasional', 2), ('nice', 2), ('coming', 2), ('puree', 2), ('saying', 1), ('tossing', 1), ('slick', 1), ('nefarious', 1), ('controversial', 1), ('ladleful', 1), ('fine', 1), ('pourable', 1), ('personal', 1), ('madman', 1), ('figuring', 1), ('homogenous', 1), ('teaching', 1), ('seasoning', 1), ('playing', 1), ('real', 1), ('flagrant', 1), ('redistributing', 1), ('sitting', 1), ('providing', 1), ('starkly', 1), ('transparent', 1), ('impressive', 1), ('garlicky', 1), ('wooden', 1), ('bluegal', 1), ('filling', 1), ('reasonable', 1), ('dangerous', 1), ('difficult', 1), ('heavy', 1), ('employing', 1), ('fair', 1), ('needless', 1), ('subsversive', 1), ('aligning', 1), ('crushing', 1), ('reduce', 1), ('recently-opened', 1), ('strongest', 1), ('unapologetic', 1), ('curious', 1), ('pale', 1), ('blonde', 1), ('subject', 1), ('splashy', 1), ('reserving', 1), ('potential', 1), ('attempting', 1), ('slide', 1), ('unable', 1), ('new', 1), ('heating', 1), ('public', 1), ('red', 1), ('measuring', 1), ('disintegrated', 1), ('slight', 1), ('minor', 1), ('outfitted', 1), ('1tbsp', 1), ('sexy', 1), ('tempering', 1), ('feeling', 1), ('many', 1), ('cupful', 1), ('according', 1), ('medium-low', 1), ('expecting', 1), ('medium-high', 1), ('whole', 1), ('requiring', 1), ('limp', 1)]\n"
     ]
    }
   ],
   "source": [
    "print candidates['stir'].most_common(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
