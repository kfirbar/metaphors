{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "import spacy as sp\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from math import log\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import DBSCAN\n",
    "from math import log\n",
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "from itertools import product\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = sp.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original metaphors loading\n",
    "\n",
    "eval_data = pd.read_csv(\"eval-mod_ours.txt\")\n",
    "\n",
    "metaphor_words = []\n",
    "metaphors = {}\n",
    "\n",
    "for r in eval_data.iterrows():\n",
    "    #tokens = nlp(r[1][\"Metaphor\"].decode('utf-8', errors='ignore').strip().lower())\n",
    "    tokens = nlp(r[1][\"Metaphor\"].strip().lower())\n",
    "    topic = tokens[0]\n",
    "    vehicle = tokens[-1]\n",
    "    if topic.lemma_ not in metaphor_words:\n",
    "        metaphor_words.append(topic.lemma_)\n",
    "    if vehicle.lemma_ not in metaphor_words:\n",
    "        metaphor_words.append(vehicle.lemma_)\n",
    "    if r[1][\"Metaphor\"] not in metaphors:\n",
    "        metaphors[r[1][\"Metaphor\"]] = [topic.lemma_, vehicle.lemma_, \n",
    "                                       [(str(r[1][\"Interpretation\"]).lower(), r[1][\"Freq\"])],\n",
    "                                       [str(r[1][\"Interpretation\"]).lower()]\n",
    "                                      ]\n",
    "    else:\n",
    "        metaphors[r[1][\"Metaphor\"]][2].append((str(r[1][\"Interpretation\"]).lower(), r[1][\"Freq\"]))\n",
    "        metaphors[r[1][\"Metaphor\"]][3].append(str(r[1][\"Interpretation\"]).lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['man', 'ox', 'body', 'spring', 'face', 'white', 'deathmask', 'sensation', 'fever', 'face', 'land', 'ghost', 'women', 'goddess', 'pain', 'knife', 'plate', 'voice', 'shower', 'rocks', 'man', 'zombie', 'body', 'armor', 'suit', 'man', 'bull', 'man', 'pitbull', 'pit-bull', 'place', 'tomb', 'destruction', 'firework', 'swamp', 'cemetery', 'pain', 'bomb', 'life', 'chemistry', 'experiment', 'man', 'gorilla', 'place', 'museum', 'i', 'whale', 'voice', 'feather', 'body', 'bowstring', 'bird', 'marble', 'thunder', 'diamond', 'rough', 'waterfall', 'geezer', 'happiness', 'fever', 'eyes', 'steel', 'music', 'heart', 'women', 'angel', 'bottomless', 'pits', 'water', 'man', 'marble', 'statue', 'man', 'horse', 'place', 'museum', 'answer', 'viper', 'hissing', 'man', 'animal', 'man', 'rock', 'love', 'oxygen', 'apartment', 'meat', 'locker', 'culture', 'food', 'fox', 'neck', 'tree', 'trunk', 'life', 'desert', 'robot', 'cheetah', 'mule', 'wallflower', 'plan', 'house', 'cards', 'words', 'slap', 'office', 'hive', 'words', 'weapon', 'love', 'unicorn', 'woman', 'stick', 'voice', 'stone', 'toad', 'decision', 'peacock', 'furniture', 'guilt', 'truck', 'house', 'cave', 'words', 'music', 'place', 'funeral', 'news', 'shower', 'doornail', 'wisdom', 'fingerprint', 'decision', 'concrete']\n"
     ]
    }
   ],
   "source": [
    "# Loading Lena's new metaphors\n",
    "\n",
    "metaphor_words = []\n",
    "with open(\"lena_metaphors_individual_words.txt\", \"rt\") as f:\n",
    "    for line in f.readlines():\n",
    "        metaphor_words.append(line.strip())\n",
    "\n",
    "\n",
    "print(metaphor_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self):\n",
    "        self.vec = []\n",
    "        self.word_count = 0\n",
    "        self.ind2word = {}\n",
    "        self.word2ind = {}\n",
    "        for line in open(\"/Users/Kfir/Documents/corpora/glove.6B/glove.6B.300d.txt\"):\n",
    "            values = line.split(\" \")\n",
    "            v = []\n",
    "            for i in range (1, len(values)):\n",
    "                v.append(float(values[i]))\n",
    "            self.vec.append(v)\n",
    "            self.ind2word[self.word_count] = values[0]\n",
    "            self.word2ind[values[0]] = self.word_count\n",
    "            self.word_count += 1\n",
    "    \n",
    "    def get_vec(self, word):\n",
    "        word = word.strip().lower()\n",
    "        if word in self.word2ind:\n",
    "            return self.vec[self.word2ind[word]]\n",
    "        return None\n",
    "            \n",
    "lang = Lang()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepNode:\n",
    "    def __init__(self, line):\n",
    "        tokens = line.split('\\t')\n",
    "        self.id = int(tokens[0])\n",
    "        self.text = tokens[1].lower()\n",
    "        self.lemma = tokens[2].lower()\n",
    "        self.pos = tokens[3]\n",
    "        self.head = int(tokens[6])\n",
    "        self.dep_type = tokens[7]\n",
    "        self.children = []\n",
    "\n",
    "class DepSentence:\n",
    "    def __init__(self):\n",
    "        self.nodes = []\n",
    "        \n",
    "    def add_word(self, line):\n",
    "        node = DepNode(line)\n",
    "        self.nodes.append(node)\n",
    "        return node\n",
    "        \n",
    "    def rewire(self):\n",
    "        for n in self.nodes:\n",
    "            if n.dep_type != 'ROOT':\n",
    "                self.nodes[n.head].children.append(n)\n",
    "    \n",
    "\n",
    "def is_valid_meaning(p):\n",
    "    #if self.pos in ['JJ', 'JJS', 'RB', 'VBG']:\n",
    "    #if p in ['JJ', 'JJS', 'VBG']:\n",
    "    if p in ['VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'VB']:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "\n",
    "def count_words(dep_corpus_folder):\n",
    "    words = 0\n",
    "    files = [f for f in os.listdir(dep_corpus_folder) if os.path.isfile(os.path.join(dep_corpus_folder, f))]\n",
    "    for f in files:\n",
    "        full_path = os.path.join(dep_corpus_folder, f)\n",
    "        print(\"processing\", full_path)\n",
    "        sentence = None\n",
    "        valid = False\n",
    "        for line in gzip.open(full_path):\n",
    "            if len(line.strip()) > 0:\n",
    "                words += 0\n",
    "                \n",
    "    print(words)\n",
    "        \n",
    "def find_candidates_for(words, dep_corpus_folder):\n",
    "    candidates = {}\n",
    "    files = [f for f in os.listdir(dep_corpus_folder) if os.path.isfile(os.path.join(dep_corpus_folder, f))]\n",
    "    for f in files:\n",
    "        full_path = os.path.join(dep_corpus_folder, f)\n",
    "        print(\"processing\", full_path)\n",
    "        sentence = None\n",
    "        valid = False\n",
    "        for line in gzip.open(full_path):\n",
    "            line = line.decode('utf-8')\n",
    "            line = line.strip()\n",
    "            if len(line) > 0 and line[0] != '#':\n",
    "                if sentence is None:\n",
    "                    sentence = DepSentence()\n",
    "                node = sentence.add_word(line)\n",
    "                if node.text in words:\n",
    "                    valid = True\n",
    "            elif sentence is not None:\n",
    "                if valid:\n",
    "                    sentence.rewire()\n",
    "                    for n in sentence.nodes:\n",
    "                        if n.text in words:\n",
    "                            if n.text not in candidates:\n",
    "                                candidates[n.text] = Counter()\n",
    "                            if n.dep_type != 'ROOT' and is_valid_meaning(sentence.nodes[n.head].pos):\n",
    "                                candidates[n.text][sentence.nodes[n.head].text] += 1\n",
    "                            for c in n.children:\n",
    "                                if is_valid_meaning(c.pos):\n",
    "                                    candidates[n.text][c.text] += 1\n",
    "                sentence = None\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing dep_corpus/part-m-00012.gz\n",
      "processing dep_corpus/part-m-00026.gz\n",
      "processing dep_corpus/part-m-00036.gz\n",
      "processing dep_corpus/part-m-00002.gz\n",
      "processing dep_corpus/part-m-00022.gz\n",
      "processing dep_corpus/part-m-00006.gz\n",
      "processing dep_corpus/part-m-00032.gz\n",
      "processing dep_corpus/part-m-00023.gz\n",
      "processing dep_corpus/part-m-00017.gz\n",
      "processing dep_corpus/part-m-00007.gz\n",
      "processing dep_corpus/part-m-00033.gz\n",
      "processing dep_corpus/part-m-00027.gz\n",
      "processing dep_corpus/part-m-00037.gz\n",
      "processing dep_corpus/part-m-00003.gz\n",
      "processing dep_corpus/part-m-00018.gz\n",
      "processing dep_corpus/part-m-00008.gz\n",
      "processing dep_corpus/part-m-00028.gz\n",
      "processing dep_corpus/part-m-00038.gz\n",
      "processing dep_corpus/part-m-00029.gz\n",
      "processing dep_corpus/part-m-00039.gz\n",
      "processing dep_corpus/part-m-00019.gz\n",
      "processing dep_corpus/part-m-00009.gz\n",
      "processing dep_corpus/part-m-00020.gz\n",
      "processing dep_corpus/part-m-00014.gz\n",
      "processing dep_corpus/part-m-00004.gz\n",
      "processing dep_corpus/part-m-00030.gz\n",
      "processing dep_corpus/part-m-00010.gz\n",
      "processing dep_corpus/part-m-00024.gz\n",
      "processing dep_corpus/part-m-00034.gz\n",
      "processing dep_corpus/part-m-00000.gz\n",
      "processing dep_corpus/part-m-00011.gz\n",
      "processing dep_corpus/part-m-00040.gz\n",
      "processing dep_corpus/part-m-00025.gz\n",
      "processing dep_corpus/part-m-00035.gz\n",
      "processing dep_corpus/part-m-00001.gz\n",
      "processing dep_corpus/part-m-00021.gz\n",
      "processing dep_corpus/part-m-00015.gz\n",
      "processing dep_corpus/part-m-00005.gz\n"
     ]
    }
   ],
   "source": [
    "candidates = find_candidates_for(metaphor_words, 'dep_corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(candidates, open( \"candidates-lena-metaphors.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('restricts', 2), ('accept', 2), ('are', 2), ('goes', 2), ('wearing', 2), ('have', 2), ('breaks', 2), ('take', 2), ('lose', 1), ('loses', 1), ('equip', 1), ('put', 1), ('called', 1), ('survive', 1), ('obtain', 1), ('mitigates', 1), ('has', 1), ('sacrifice', 1), ('come', 1), ('earn', 1), ('wear', 1), ('got', 1), ('gaining', 1), ('means', 1), ('grants', 1), ('added', 1), ('was', 1), ('is', 1), ('calls', 1), ('shining', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(candidates['armor'].most_common(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
